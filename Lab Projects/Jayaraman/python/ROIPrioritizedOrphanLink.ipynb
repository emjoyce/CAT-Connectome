{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Prioritized Orphan Link\n",
    "- this code takes data from the file OL_roi_continuation_analysis\n",
    "- runs the orphan link query based on desired level of completedness, prioritizes bodies in ROIs with high continuation rates\n",
    "- enter desired level of completeness below in a decimal between 0.0-1.0 (completion_goal)\n",
    "- enter the predicted merge rate of orphans (merge_rate)\n",
    "- enter the direction, \"up\" to get upstream orphans of your body IDs, or \"down\" to get downstream orphans of your bodies. Format : direction = \"up\" or direction = \"down\"\n",
    "- enter the body ID list in the format body_id_list = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_goal = .45\n",
    "\n",
    "merge_rate = .60\n",
    "\n",
    "direction = \"up\"\n",
    "\n",
    "body_id_list = [5813063239, 603785283, 850717220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your neuprint token here, in the format: token = 'abcde.12345'\n",
    "\n",
    "get your 'auth token' here for most recent data: https://neuprint-test.janelia.org/account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImVtaWx5Lm0uam95Y2UxQGdtYWlsLmNvbSIsImxldmVsIjoicmVhZHdyaXRlIiwiaW1hZ2UtdXJsIjoiaHR0cHM6Ly9saDUuZ29vZ2xldXNlcmNvbnRlbnQuY29tLy1rQ3BqVXpRc3BuNC9BQUFBQUFBQUFBSS9BQUFBQUFBQUFBQS9BTVp1dWNrOEhwVlhrUHV4My1HZXRldjcwbXd1TFdqMVBnL3Bob3RvLmpwZz9zej01MD9zej01MCIsImV4cCI6MTc4MDI3NzU3M30.WaXfZwra0QId3alTewbxTqkvklJ8wQf9lkFXGuV4rCM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioritized_rois = [\"AL(R)\",\"MB(+ACA)(R)\",\"VLNP(R)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neuprint as neu\n",
    "import json\n",
    "\n",
    "from neuprint import Client, fetch_custom\n",
    "c = Client('neuprint-test.janelia.org', dataset='hemibrain', token = token, verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the arrow direction for upstream or downstream\n",
    "def direction_arrow(direction):\n",
    "    if direction.lower() == \"up\" or \"upstream\":\n",
    "        direction = \"-[w:ConnectsTo]->\"\n",
    "    elif direction.lower() == \"down\" or \"downstream\":\n",
    "        direction = \"<-[w:ConnectsTo]-\"\n",
    "    else:\n",
    "        raise TypeError(\"direction must be 'up' or 'down', you have entered \" + direction)\n",
    "    return direction\n",
    "direction = direction_arrow(direction)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion percent query\n",
    "- calculates the up/downstream completion percent, (total \"traced\" weight / total downstream weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_rate': 0.26527805069758303,\n",
       " 'total_weight': 10178,\n",
       " 'total_completed_weight': 2700}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def completion_percent(body):\n",
    "    \n",
    "    # find the total downstream neurons\n",
    "    total_q = fetch_custom(\"\"\"\n",
    "    MATCH (a:Neuron)\"\"\" + direction + \"\"\"(b:Segment) \n",
    "    WHERE a.bodyId = \"\"\" + str(body) + \"\"\" \n",
    "    RETURN sum(w.weight)\"\"\")\n",
    "    \n",
    "    total_weight = total_q.iloc[0,0]\n",
    "    \n",
    "    # find the downstream neurons with a status of traced or leaves \n",
    "    # alternatively could do no no statuses, but could be assign\n",
    "    status_q = fetch_custom(\"\"\"\n",
    "    MATCH (a:Neuron)\"\"\" + direction + \"\"\"(b:Segment)\n",
    "    WHERE a.bodyId = \"\"\" + str(body) + \"\"\" AND (b.status CONTAINS \"raced\" OR b.status CONTAINS \"eaves\") \n",
    "    RETURN sum(w.weight)\n",
    "    \"\"\") \n",
    "    \n",
    "    total_completed_weight = status_q.iloc[0,0]\n",
    "    \n",
    "    \n",
    "    completion_rate = total_completed_weight/total_weight\n",
    "    \n",
    "    return({'completion_rate':completion_rate, 'total_weight':total_weight, 'total_completed_weight':total_completed_weight})\n",
    "    \n",
    "completion_percent(5813063239)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orphans Query\n",
    "- returns all the orphans up/downstream of your body and the ROIs they innervate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b.bodyId</th>\n",
       "      <th>(b.pre+b.post)</th>\n",
       "      <th>b.roiInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070321500</td>\n",
       "      <td>18</td>\n",
       "      <td>{\"AL(R)\": {\"post\": 18}, \"AL-VP3(R)\": {\"post\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2627581366</td>\n",
       "      <td>10</td>\n",
       "      <td>{\"GNG\": {\"pre\": 1, \"post\": 8, \"downstream\": 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226503253</td>\n",
       "      <td>10</td>\n",
       "      <td>{\"VLNP(R)\": {\"post\": 10}, \"PLP(R)\": {\"post\": 10}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2288580553</td>\n",
       "      <td>9</td>\n",
       "      <td>{\"AL(R)\": {\"post\": 9}, \"AL-VP5(R)\": {\"post\": 9}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>853057088</td>\n",
       "      <td>9</td>\n",
       "      <td>{\"INP\": {\"post\": 9}, \"SCL(R)\": {\"post\": 9}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>697524064</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>1069947590</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"INP\": {\"post\": 1}, \"SCL(R)\": {\"post\": 1}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>1069606392</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"INP\": {\"post\": 1}, \"SCL(R)\": {\"post\": 1}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>728904247</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>728904260</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6064 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        b.bodyId  (b.pre+b.post)  \\\n",
       "0     2070321500              18   \n",
       "1     2627581366              10   \n",
       "2     1226503253              10   \n",
       "3     2288580553               9   \n",
       "4      853057088               9   \n",
       "...          ...             ...   \n",
       "6059   697524064               1   \n",
       "6060  1069947590               1   \n",
       "6061  1069606392               1   \n",
       "6062   728904247               1   \n",
       "6063   728904260               1   \n",
       "\n",
       "                                              b.roiInfo  \n",
       "0     {\"AL(R)\": {\"post\": 18}, \"AL-VP3(R)\": {\"post\": ...  \n",
       "1     {\"GNG\": {\"pre\": 1, \"post\": 8, \"downstream\": 11...  \n",
       "2     {\"VLNP(R)\": {\"post\": 10}, \"PLP(R)\": {\"post\": 10}}  \n",
       "3      {\"AL(R)\": {\"post\": 9}, \"AL-VP5(R)\": {\"post\": 9}}  \n",
       "4           {\"INP\": {\"post\": 9}, \"SCL(R)\": {\"post\": 9}}  \n",
       "...                                                 ...  \n",
       "6059     {\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}  \n",
       "6060        {\"INP\": {\"post\": 1}, \"SCL(R)\": {\"post\": 1}}  \n",
       "6061        {\"INP\": {\"post\": 1}, \"SCL(R)\": {\"post\": 1}}  \n",
       "6062     {\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}  \n",
       "6063     {\"SNP(R)\": {\"post\": 1}, \"SLP(R)\": {\"post\": 1}}  \n",
       "\n",
       "[6064 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orphan_query(body):\n",
    "    \n",
    "    orphans = fetch_custom(\"\"\"\n",
    "    MATCH (a:Neuron)\"\"\" + direction + \"\"\"(b:Segment)\n",
    "    WHERE a.bodyId = \"\"\" + str(body) + \"\"\" AND (b.status IS NULL OR b.status CONTAINS \"ssign\") \n",
    "    RETURN b.bodyId, (b.pre+b.post), b.roiInfo, b.size\n",
    "    ORDER BY (b.pre+b.post) DESC, b.size desc\n",
    "    \"\"\")\n",
    "    \n",
    "    return orphans\n",
    "\n",
    "orphan_query(5813063239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function: returns orphans, prioritized by size and ROI\n",
    "- will first report all orphans with more than 4 total synapses or from regions with high continuation rates\n",
    "- will then finish off with the rest of the orphans ordered by number of synapses and the voxel size of the orphan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orphans(body_id_list):\n",
    "    \n",
    "    final_orphans = pd.DataFrame()\n",
    "    \n",
    "    for body in body_id_list:\n",
    "        \n",
    "        # create a running count for orphan weight. We will continue adding bodies until \n",
    "        # (orphan_weight + total_completed_weight) / total_weight >= completion_goal\n",
    "        orphan_weight = 0\n",
    "        \n",
    "        # create a list of orphans for this body to include and to exclude\n",
    "        # we will add the excluded orphans to the OL list in the end\n",
    "        # only if we there are not enough prioritized orphans to reach the completion goal\n",
    "        included_orphans = []\n",
    "        excluded_orphans = pd.DataFrame(columns = ['b.bodyId', '(b.pre+b.post)'])\n",
    "        \n",
    "        # pull the full orphan list for the body\n",
    "        full_orphan_list = orphan_query(body)\n",
    "        \n",
    "        # retreive completion numbers \n",
    "        comp_dict = completion_percent(body)\n",
    "        completion_rate = comp_dict['completion_rate']\n",
    "        total_weight = comp_dict['total_weight']\n",
    "        total_completed_weight = comp_dict['total_completed_weight']\n",
    "        \n",
    "        \n",
    "        # we will calculate the number of new synapses that need to be traced out\n",
    "        # to reach out goal. we will use the assumed merge rate parameter.  \n",
    "        syn_goal = ((completion_goal*total_weight)-total_completed_weight)/merge_rate\n",
    "        \n",
    "        # go orphan by orphan and add\n",
    "        for orphan, row in full_orphan_list.iterrows():\n",
    "            \n",
    "            roi_dict = full_orphan_list.loc[orphan,\"b.roiInfo\"]\n",
    "            \n",
    "            # go row by row and add to the OL list if it has 4+ synapses or is in a high merge ROI\n",
    "            if orphan_weight < syn_goal:\n",
    "                if full_orphan_list.iloc[orphan,1] > 3:\n",
    "                    included_orphans.append(row[\"b.bodyId\"])\n",
    "                    orphan_weight += full_orphan_list.iloc[orphan,1]\n",
    "                    continue\n",
    "                elif (not(set(roi_dict)&set(prioritized_rois))==set()): # if an roi is a prioritized one\n",
    "                    included_orphans.append(row[\"b.bodyId\"])\n",
    "                    orphan_weight += full_orphan_list.iloc[orphan,1]\n",
    "                    continue\n",
    "                else:\n",
    "                    new_row = {'b.bodyId':full_orphan_list.iloc[orphan,0], '(b.pre+b.post)': full_orphan_list.iloc[orphan,1]}\n",
    "                    excluded_orphans = excluded_orphans.append(new_row, ignore_index=True)\n",
    "                    \n",
    "        # go row by row and add deprioritized ROIs/small orphans by size \n",
    "        \n",
    "            \n",
    "        for orphan, row in excluded_orphans.iterrows():\n",
    "            current_completion_rate = (orphan_weight + total_completed_weight)/total_weight\n",
    "            if orphan_weight < syn_goal:\n",
    "                included_orphans.append(excluded_orphans.iloc[orphan,0])\n",
    "                orphan_weight += excluded_orphans.iloc[orphan,1]\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        orphans_df = pd.DataFrame({body:included_orphans})\n",
    "        \n",
    "        final_orphans = pd.concat([final_orphans, orphans_df], axis=1).drop_duplicates().fillna('')\n",
    "        \n",
    "    return (final_orphans)\n",
    "orphans=orphans(body_id_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     5813063239    603785283     850717220 \n",
       " 0    2070321500  2.102034e+09  2.038950e+09\n",
       " 1    2627581366  7.575907e+08  2.102034e+09\n",
       " 2    1226503253  6.951590e+08  1.066524e+09\n",
       " 3    2288580553  2.100342e+09  1.004788e+09\n",
       " 4     853057088  2.225824e+09  8.185994e+08\n",
       " ..          ...           ...           ...\n",
       " 463   788923749           NaN           NaN\n",
       " 464   853057179           NaN           NaN\n",
       " 465   788923448           NaN           NaN\n",
       " 466   729950158           NaN           NaN\n",
       " 467   822716987           NaN           NaN\n",
       " \n",
       " [468 rows x 3 columns],)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results by running this cell\n",
    "\n",
    "orphans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the results by running this cell. \n",
    "# The file will be saved in whatever file this jupyter notebook file is stored in. (If run in MyBinder, will be in Jupyter Notebook file navigator)  \n",
    "# The red text below will be the name that this file is saved as, so you can change it to whatever name you need. \n",
    "\n",
    "orphans.to_csv(\"orphan_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuprint-python",
   "language": "python",
   "name": "neuprint-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}