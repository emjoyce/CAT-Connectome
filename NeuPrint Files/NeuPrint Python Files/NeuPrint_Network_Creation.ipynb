{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This script enables one to extract connectivity information from the NeuPrint API (https://neuprint.janelia.org/) for the purpose of creating a gexf network file. The gexf format allows each node to possess additional label information that might include its voxel size, brain region ROIs (regions of interest), net connectivity weight, etc. Once the gexf file has been generated, it can be viewed and manipulated using the robust tools of the program Gephi (https://gephi.org/)__ \n",
    "\n",
    "___Inputs___ <br>\n",
    "_FIBSEM ID LIST_: list type; the list should consist of hemibrain Body IDs (from NeuPrint), seperated by commas <br>\n",
    "_Min Voxels_: integer type; if the network consists of fragments that border the edge of the volume, one might want to remove all Body IDs below a certain voxel threshold.  <br>\n",
    "_Min Weight_: integer type; remove any connections below a certain weight threshold  <br>\n",
    "_dataset_: string type; choose which of the three versions of the hemibrain dataset you'd like to extract the information from ('hemibrain:v1.0.1', 'hemibrain:v1.1', 'hemibrain:v1.2') <br>\n",
    "_token ID_: string type; the authentication token can be found on the NeuPrint page under the user profile <br>\n",
    "\n",
    "\n",
    "___Output___\n",
    "_gefx file_: this network file can be imported to the program Gephi, to conduct further analysis and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuPrint_Multigraph(FIBSEM_ID_LIST, Min_Voxels, Min_Weight, dataset, token_ID):#Recommend Min_Voxels=16000000, and Min_Weight=3 \n",
    "    import networkx as nx\n",
    "    from neuprint import Client\n",
    "    from neuprint import fetch_adjacencies\n",
    "    from neuprint import fetch_neurons\n",
    "    \n",
    "    #establish Client\n",
    "    c = Client('neuprint.janelia.org', dataset=str(dataset), token=str(token_ID))\n",
    "    print(c.fetch_version())\n",
    "    \n",
    "    InputOutputList = []\n",
    "    G = nx.MultiDiGraph()\n",
    "    \n",
    "    \n",
    "    for Neuron in FIBSEM_ID_LIST:\n",
    "        try:\n",
    "            print(Neuron)\n",
    "            #import input and output dataframes from NeuPrint\n",
    "            neuron_dfin, inputs_df = fetch_adjacencies(None, [Neuron])\n",
    "            neuron_dfout, outputs_df = fetch_adjacencies([Neuron],None)\n",
    "            print(\"Done!\")\n",
    "            #create graph and FIBSEM_ID node\n",
    "            G.add_node(Neuron)\n",
    "            #add size attribute to FIBSEM_ID node \n",
    "            neuron_df, roi_counts_df = fetch_neurons(Neuron)\n",
    "            G.node[Neuron]['size'] = int(neuron_df['size'])\n",
    "            #add neuropil attribute to node\n",
    "            G.node[Neuron]['roi'] = str(roi_counts_df['roi'].max())\n",
    "            #add input nodes to G and create edges with original bodyID\n",
    "            for index, r1 in inputs_df.iterrows():\n",
    "                fetch_temp, roi_counts_df = fetch_neurons(r1['bodyId_pre'])\n",
    "                #skip ID if below size minimum\n",
    "                if int(fetch_temp['size']) < Min_Voxels:\n",
    "                    continue\n",
    "                #skip ID if orphan\n",
    "                A=fetch_temp[\"status\"].to_string()\n",
    "                if A[5:11] == 'Orphan':\n",
    "                    continue\n",
    "                #skip ID if below minimum connection weight\n",
    "                if int(r1['weight']) < Min_Weight:\n",
    "                    continue\n",
    "                #add ID node to graph\n",
    "                G.add_node(r1['bodyId_pre'])\n",
    "                #add size attribute to node\n",
    "                G.node[r1['bodyId_pre']]['size'] = int(fetch_temp['size'])\n",
    "                #add neuropil attribute to node\n",
    "                G.node[r1['bodyId_pre']]['roi'] = str(roi_counts_df['roi'].max())\n",
    "                #add edges to graph\n",
    "                for n in range(int(r1['weight'])):\n",
    "                    G.add_edge(str(r1['bodyId_pre']),str(Neuron)) \n",
    "                #add bodyID to input/output list\n",
    "                InputOutputList.append(r1['bodyId_pre']) \n",
    "            #add output nodes to G and create edges with original bodyID                     \n",
    "            for index, r1 in outputs_df.iterrows():\n",
    "                fetch_temp, roi_counts_df = fetch_neurons(r1['bodyId_post'])\n",
    "                #skip ID if below size minimum\n",
    "                if int(fetch_temp['size']) < Min_Voxels:\n",
    "                    continue\n",
    "                #skip ID if orphan\n",
    "                A=fetch_temp[\"status\"].to_string()\n",
    "                if A[5:11] == 'Orphan':\n",
    "                    continue\n",
    "                #skip ID if below minimum connection weight\n",
    "                if int(r1['weight']) < Min_Weight:\n",
    "                    continue\n",
    "                #add ID node to graph\n",
    "                G.add_node(r1['bodyId_post'])\n",
    "                #add size attribute to node\n",
    "                G.node[r1['bodyId_post']]['size'] = int(fetch_temp['size'])\n",
    "                #add neuropil attribute to node\n",
    "                G.node[r1['bodyId_post']]['roi'] = str(roi_counts_df['roi'].max())\n",
    "                #add edges to graph\n",
    "                for n in range(int(r1['weight'])):\n",
    "                    G.add_edge(str(Neuron),str(r1['bodyId_post']))\n",
    "                #add bodyID to input/output list\n",
    "                InputOutputList.append(r1['bodyId_post'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #remove duplicates from input/output list\n",
    "    InputOutputList1 = list( dict.fromkeys(InputOutputList) )\n",
    "    #remove original IDs from input/output list\n",
    "    InputOutputList2 = [i for i in InputOutputList1 if i not in FIBSEM_ID_LIST]\n",
    "    \n",
    "    #add edges between inputs/outputs of original bodyIDs\n",
    "    for id1 in InputOutputList2:\n",
    "        try:\n",
    "            fetch_temp, temp_inputs_df = fetch_adjacencies(None, [id1])\n",
    "            for index, r1 in temp_inputs_df.iterrows():\n",
    "                if int(r1['weight']) < Min_Weight:\n",
    "                        continue\n",
    "                for id2 in InputOutputList2:\n",
    "                    if r1['bodyId_pre'] == id2:\n",
    "                        for r in range(int(r1['weight'])):\n",
    "                            G.add_edge(str(id2),str(id1))\n",
    "        #if there's an error in creating the bodyID dataframe\n",
    "        except:\n",
    "            print(\"The connectivity dataframe of the bodyID\",id1,\"encountered an error.\")\n",
    "            pass\n",
    "        \n",
    "    #remove edges between original ID list\n",
    "    for ID1 in FIBSEM_ID_LIST:\n",
    "        for ID2 in FIBSEM_ID_LIST:\n",
    "            try:\n",
    "                E = G.number_of_edges(str(ID1),str(ID2))\n",
    "                for i in range(E):\n",
    "                    G.remove_edge(str(ID1),str(ID2))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    #add edges back between original ID list\n",
    "    for ID1 in FIBSEM_ID_LIST:\n",
    "        for ID2 in FIBSEM_ID_LIST:\n",
    "            try:\n",
    "                fetch_temp, inputs_df = fetch_adjacencies([ID1],[ID2])\n",
    "                E = sum(inputs_df['weight'])\n",
    "                #skip ID if below minimum connection weight\n",
    "                if int(E) < Min_Weight:\n",
    "                    continue\n",
    "                for i in range(E):\n",
    "                    G.add_edge(str(ID1),str(ID2))\n",
    "               \n",
    "            #if there's an error in creating the bodyID dataframe\n",
    "            except:\n",
    "                pass  \n",
    "\n",
    "        \n",
    "    #write gefx file for use in Gephi\n",
    "    nx.write_gexf(G, 'Atest'+'.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
